{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eccd4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c098e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, mean_squared_error\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2006ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel43</th>\n",
       "      <th>pixel44</th>\n",
       "      <th>pixel92</th>\n",
       "      <th>pixel124</th>\n",
       "      <th>pixel125</th>\n",
       "      <th>pixel126</th>\n",
       "      <th>pixel127</th>\n",
       "      <th>pixel128</th>\n",
       "      <th>pixel129</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel329</th>\n",
       "      <th>pixel351</th>\n",
       "      <th>pixel410</th>\n",
       "      <th>pixel411</th>\n",
       "      <th>pixel412</th>\n",
       "      <th>pixel413</th>\n",
       "      <th>pixel414</th>\n",
       "      <th>pixel415</th>\n",
       "      <th>pixel416</th>\n",
       "      <th>pixel417</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>137</td>\n",
       "      <td>192</td>\n",
       "      <td>86</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>141</td>\n",
       "      <td>139</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>255</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>157</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>248</td>\n",
       "      <td>253</td>\n",
       "      <td>176</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>253</td>\n",
       "      <td>229</td>\n",
       "      <td>133</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel43  pixel44  pixel92  pixel124  pixel125  pixel126  \\\n",
       "0          1        0        0        0         0         0         0   \n",
       "1          0        0        0        0       137       137       192   \n",
       "2          1        0        0        0         3       141       139   \n",
       "3          4        0        0        0         0         0         0   \n",
       "4          0        0        0        0       155       254       254   \n",
       "...      ...      ...      ...      ...       ...       ...       ...   \n",
       "41995      2        0        0        1       248       253       176   \n",
       "41996      0        0        0        0         0         0         0   \n",
       "41997      2        0        0        0       255       255       191   \n",
       "41998      2        0        0        0       255       128         0   \n",
       "41999      2        0        0      227       253       229       133   \n",
       "\n",
       "       pixel127  pixel128  pixel129  ...  pixel329  pixel351  pixel410  \\\n",
       "0             0         0         0  ...         0       254         0   \n",
       "1            86        72         1  ...       254         0         0   \n",
       "2             3         0         0  ...         0       184         0   \n",
       "3             0         0         0  ...         0         0        94   \n",
       "4           254       157        30  ...       253         0         0   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "41995        43         0         0  ...         0         0         0   \n",
       "41996         0         0       128  ...         0         0         0   \n",
       "41997         0         0         0  ...         0         0         0   \n",
       "41998         0         0         0  ...         0       255         0   \n",
       "41999        19         0         0  ...         0         0       253   \n",
       "\n",
       "       pixel411  pixel412  pixel413  pixel414  pixel415  pixel416  pixel417  \n",
       "0             0         0         0         0         0         0         0  \n",
       "1            75       254       254       254        17         0         0  \n",
       "2             0         0         0         0         0         0         0  \n",
       "3           255        69         0         0         0         0         0  \n",
       "4             0       223       253       253       253       129         0  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0         0         0  \n",
       "41996         0       255       255         0         0         0         0  \n",
       "41997         0         0         0         0         0         0         0  \n",
       "41998         0         0         0         0         0         0         0  \n",
       "41999       160         1         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import Dataset\n",
    "df = pd.read_csv(\"C:/Users/Dell/Downloads/letters.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d0698ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label', 'pixel43', 'pixel44', 'pixel92', 'pixel124', 'pixel125',\n",
      "       'pixel126', 'pixel127', 'pixel128', 'pixel129', 'pixel130', 'pixel131',\n",
      "       'pixel132', 'pixel133', 'pixel134', 'pixel135', 'pixel136', 'pixel137',\n",
      "       'pixel138', 'pixel146', 'pixel147', 'pixel148', 'pixel149', 'pixel150',\n",
      "       'pixel151', 'pixel152', 'pixel153', 'pixel154', 'pixel155', 'pixel156',\n",
      "       'pixel157', 'pixel158', 'pixel159', 'pixel160', 'pixel327', 'pixel328',\n",
      "       'pixel329', 'pixel351', 'pixel410', 'pixel411', 'pixel412', 'pixel413',\n",
      "       'pixel414', 'pixel415', 'pixel416', 'pixel417'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db4b13f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Data columns (total 46 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   label     42000 non-null  int64\n",
      " 1   pixel43   42000 non-null  int64\n",
      " 2   pixel44   42000 non-null  int64\n",
      " 3   pixel92   42000 non-null  int64\n",
      " 4   pixel124  42000 non-null  int64\n",
      " 5   pixel125  42000 non-null  int64\n",
      " 6   pixel126  42000 non-null  int64\n",
      " 7   pixel127  42000 non-null  int64\n",
      " 8   pixel128  42000 non-null  int64\n",
      " 9   pixel129  42000 non-null  int64\n",
      " 10  pixel130  42000 non-null  int64\n",
      " 11  pixel131  42000 non-null  int64\n",
      " 12  pixel132  42000 non-null  int64\n",
      " 13  pixel133  42000 non-null  int64\n",
      " 14  pixel134  42000 non-null  int64\n",
      " 15  pixel135  42000 non-null  int64\n",
      " 16  pixel136  42000 non-null  int64\n",
      " 17  pixel137  42000 non-null  int64\n",
      " 18  pixel138  42000 non-null  int64\n",
      " 19  pixel146  42000 non-null  int64\n",
      " 20  pixel147  42000 non-null  int64\n",
      " 21  pixel148  42000 non-null  int64\n",
      " 22  pixel149  42000 non-null  int64\n",
      " 23  pixel150  42000 non-null  int64\n",
      " 24  pixel151  42000 non-null  int64\n",
      " 25  pixel152  42000 non-null  int64\n",
      " 26  pixel153  42000 non-null  int64\n",
      " 27  pixel154  42000 non-null  int64\n",
      " 28  pixel155  42000 non-null  int64\n",
      " 29  pixel156  42000 non-null  int64\n",
      " 30  pixel157  42000 non-null  int64\n",
      " 31  pixel158  42000 non-null  int64\n",
      " 32  pixel159  42000 non-null  int64\n",
      " 33  pixel160  42000 non-null  int64\n",
      " 34  pixel327  42000 non-null  int64\n",
      " 35  pixel328  42000 non-null  int64\n",
      " 36  pixel329  42000 non-null  int64\n",
      " 37  pixel351  42000 non-null  int64\n",
      " 38  pixel410  42000 non-null  int64\n",
      " 39  pixel411  42000 non-null  int64\n",
      " 40  pixel412  42000 non-null  int64\n",
      " 41  pixel413  42000 non-null  int64\n",
      " 42  pixel414  42000 non-null  int64\n",
      " 43  pixel415  42000 non-null  int64\n",
      " 44  pixel416  42000 non-null  int64\n",
      " 45  pixel417  42000 non-null  int64\n",
      "dtypes: int64(46)\n",
      "memory usage: 14.7 MB\n",
      "None\n",
      "              label       pixel43       pixel44       pixel92      pixel124  \\\n",
      "count  42000.000000  42000.000000  42000.000000  42000.000000  42000.000000   \n",
      "mean       4.456643      0.171357      0.164476      1.192833     28.043952   \n",
      "std        2.887730      5.726352      5.515774     14.692403     70.505431   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        4.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max        9.000000    255.000000    255.000000    255.000000    255.000000   \n",
      "\n",
      "           pixel125      pixel126      pixel127      pixel128      pixel129  \\\n",
      "count  42000.000000  42000.000000  42000.000000  42000.000000  42000.000000   \n",
      "mean      36.084976     42.713952     46.092310     44.542452     38.948524   \n",
      "std       78.631145     84.390533     87.287033     85.740313     81.223946   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000     10.000000     29.000000     21.000000      0.000000   \n",
      "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
      "\n",
      "       ...      pixel329      pixel351      pixel410      pixel411  \\\n",
      "count  ...  42000.000000  42000.000000  42000.000000  42000.000000   \n",
      "mean   ...     42.461048    102.124119    107.683952     79.750548   \n",
      "std    ...     85.090524    110.961953    111.360981    104.287852   \n",
      "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "50%    ...      0.000000     39.000000     60.000000      0.000000   \n",
      "75%    ...     10.000000    247.000000    250.000000    191.000000   \n",
      "max    ...    255.000000    255.000000    255.000000    255.000000   \n",
      "\n",
      "          pixel412      pixel413      pixel414      pixel415      pixel416  \\\n",
      "count  42000.00000  42000.000000  42000.000000  42000.000000  42000.000000   \n",
      "mean      56.31481     39.244643     25.754262     14.858619      5.844476   \n",
      "std       94.20847     82.799118     69.597297     54.018163     33.293343   \n",
      "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%       86.00000      0.000000      0.000000      0.000000      0.000000   \n",
      "max      255.00000    255.000000    255.000000    255.000000    255.000000   \n",
      "\n",
      "           pixel417  \n",
      "count  42000.000000  \n",
      "mean       0.829643  \n",
      "std       11.818307  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%        0.000000  \n",
      "max      255.000000  \n",
      "\n",
      "[8 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a075db18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       0\n",
       "pixel43     0\n",
       "pixel44     0\n",
       "pixel92     0\n",
       "pixel124    0\n",
       "pixel125    0\n",
       "pixel126    0\n",
       "pixel127    0\n",
       "pixel128    0\n",
       "pixel129    0\n",
       "pixel130    0\n",
       "pixel131    0\n",
       "pixel132    0\n",
       "pixel133    0\n",
       "pixel134    0\n",
       "pixel135    0\n",
       "pixel136    0\n",
       "pixel137    0\n",
       "pixel138    0\n",
       "pixel146    0\n",
       "pixel147    0\n",
       "pixel148    0\n",
       "pixel149    0\n",
       "pixel150    0\n",
       "pixel151    0\n",
       "pixel152    0\n",
       "pixel153    0\n",
       "pixel154    0\n",
       "pixel155    0\n",
       "pixel156    0\n",
       "pixel157    0\n",
       "pixel158    0\n",
       "pixel159    0\n",
       "pixel160    0\n",
       "pixel327    0\n",
       "pixel328    0\n",
       "pixel329    0\n",
       "pixel351    0\n",
       "pixel410    0\n",
       "pixel411    0\n",
       "pixel412    0\n",
       "pixel413    0\n",
       "pixel414    0\n",
       "pixel415    0\n",
       "pixel416    0\n",
       "pixel417    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull ()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "260ce15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel43</th>\n",
       "      <th>pixel44</th>\n",
       "      <th>pixel92</th>\n",
       "      <th>pixel124</th>\n",
       "      <th>pixel125</th>\n",
       "      <th>pixel126</th>\n",
       "      <th>pixel127</th>\n",
       "      <th>pixel128</th>\n",
       "      <th>pixel129</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel329</th>\n",
       "      <th>pixel351</th>\n",
       "      <th>pixel410</th>\n",
       "      <th>pixel411</th>\n",
       "      <th>pixel412</th>\n",
       "      <th>pixel413</th>\n",
       "      <th>pixel414</th>\n",
       "      <th>pixel415</th>\n",
       "      <th>pixel416</th>\n",
       "      <th>pixel417</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.171357</td>\n",
       "      <td>0.164476</td>\n",
       "      <td>1.192833</td>\n",
       "      <td>28.043952</td>\n",
       "      <td>36.084976</td>\n",
       "      <td>42.713952</td>\n",
       "      <td>46.092310</td>\n",
       "      <td>44.542452</td>\n",
       "      <td>38.948524</td>\n",
       "      <td>...</td>\n",
       "      <td>42.461048</td>\n",
       "      <td>102.124119</td>\n",
       "      <td>107.683952</td>\n",
       "      <td>79.750548</td>\n",
       "      <td>56.31481</td>\n",
       "      <td>39.244643</td>\n",
       "      <td>25.754262</td>\n",
       "      <td>14.858619</td>\n",
       "      <td>5.844476</td>\n",
       "      <td>0.829643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>5.726352</td>\n",
       "      <td>5.515774</td>\n",
       "      <td>14.692403</td>\n",
       "      <td>70.505431</td>\n",
       "      <td>78.631145</td>\n",
       "      <td>84.390533</td>\n",
       "      <td>87.287033</td>\n",
       "      <td>85.740313</td>\n",
       "      <td>81.223946</td>\n",
       "      <td>...</td>\n",
       "      <td>85.090524</td>\n",
       "      <td>110.961953</td>\n",
       "      <td>111.360981</td>\n",
       "      <td>104.287852</td>\n",
       "      <td>94.20847</td>\n",
       "      <td>82.799118</td>\n",
       "      <td>69.597297</td>\n",
       "      <td>54.018163</td>\n",
       "      <td>33.293343</td>\n",
       "      <td>11.818307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>86.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.00000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label       pixel43       pixel44       pixel92      pixel124  \\\n",
       "count  42000.000000  42000.000000  42000.000000  42000.000000  42000.000000   \n",
       "mean       4.456643      0.171357      0.164476      1.192833     28.043952   \n",
       "std        2.887730      5.726352      5.515774     14.692403     70.505431   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        4.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        9.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel125      pixel126      pixel127      pixel128      pixel129  \\\n",
       "count  42000.000000  42000.000000  42000.000000  42000.000000  42000.000000   \n",
       "mean      36.084976     42.713952     46.092310     44.542452     38.948524   \n",
       "std       78.631145     84.390533     87.287033     85.740313     81.223946   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000     10.000000     29.000000     21.000000      0.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "       ...      pixel329      pixel351      pixel410      pixel411  \\\n",
       "count  ...  42000.000000  42000.000000  42000.000000  42000.000000   \n",
       "mean   ...     42.461048    102.124119    107.683952     79.750548   \n",
       "std    ...     85.090524    110.961953    111.360981    104.287852   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000     39.000000     60.000000      0.000000   \n",
       "75%    ...     10.000000    247.000000    250.000000    191.000000   \n",
       "max    ...    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "          pixel412      pixel413      pixel414      pixel415      pixel416  \\\n",
       "count  42000.00000  42000.000000  42000.000000  42000.000000  42000.000000   \n",
       "mean      56.31481     39.244643     25.754262     14.858619      5.844476   \n",
       "std       94.20847     82.799118     69.597297     54.018163     33.293343   \n",
       "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       86.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      255.00000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel417  \n",
       "count  42000.000000  \n",
       "mean       0.829643  \n",
       "std       11.818307  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max      255.000000  \n",
       "\n",
       "[8 rows x 46 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "877e0e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d22d4a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.23.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.13)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.56.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.22.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.20.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0f70fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Value: 3\n",
      "Accuracy: 0.6303571428571428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       853\n",
      "           1       0.74      0.95      0.83       934\n",
      "           2       0.58      0.65      0.61       851\n",
      "           3       0.52      0.54      0.53       847\n",
      "           4       0.55      0.55      0.55       810\n",
      "           5       0.58      0.54      0.56       728\n",
      "           6       0.86      0.88      0.87       806\n",
      "           7       0.49      0.48      0.48       871\n",
      "           8       0.65      0.47      0.54       848\n",
      "           9       0.46      0.34      0.39       852\n",
      "\n",
      "    accuracy                           0.63      8400\n",
      "   macro avg       0.62      0.63      0.62      8400\n",
      "weighted avg       0.62      0.63      0.62      8400\n",
      "\n",
      "----------\n",
      "K Value: 7\n",
      "Accuracy: 0.6577380952380952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       853\n",
      "           1       0.76      0.95      0.84       934\n",
      "           2       0.66      0.65      0.65       851\n",
      "           3       0.58      0.58      0.58       847\n",
      "           4       0.67      0.53      0.59       810\n",
      "           5       0.63      0.55      0.59       728\n",
      "           6       0.85      0.90      0.87       806\n",
      "           7       0.47      0.60      0.53       871\n",
      "           8       0.65      0.50      0.56       848\n",
      "           9       0.46      0.40      0.43       852\n",
      "\n",
      "    accuracy                           0.66      8400\n",
      "   macro avg       0.66      0.65      0.65      8400\n",
      "weighted avg       0.66      0.66      0.65      8400\n",
      "\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Build the KNN models with different values of K\n",
    "k_values = [3, 7]  # Example values, you can adjust as per your needs\n",
    "\n",
    "for k in k_values:\n",
    "    # Create the KNN model\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Train the model\n",
    "    knn_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"K Value:\", k)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ce703e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trees: 100\n",
      "Accuracy: 0.6914285714285714\n",
      "----------\n",
      "Number of Trees: 200\n",
      "Accuracy: 0.6965476190476191\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Build the Random Forest model with different numbers of trees\n",
    "num_trees = [100, 200]  # Example values, you can adjust as per your needs\n",
    "\n",
    "for n in num_trees:\n",
    "    # Create the Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators=n)\n",
    "\n",
    "    # Train the model\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Number of Trees:\", n)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b26696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with ReLU activation: 0.6892857142857143\n",
      "Accuracy with Tanh activation: 0.6827380952380953\n",
      "Classification Report with ReLU activation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       848\n",
      "           1       0.85      0.95      0.90       975\n",
      "           2       0.68      0.67      0.67       843\n",
      "           3       0.61      0.63      0.62       830\n",
      "           4       0.75      0.56      0.64       776\n",
      "           5       0.68      0.61      0.64       795\n",
      "           6       0.91      0.87      0.89       836\n",
      "           7       0.47      0.71      0.57       839\n",
      "           8       0.62      0.54      0.58       806\n",
      "           9       0.51      0.42      0.46       852\n",
      "\n",
      "    accuracy                           0.69      8400\n",
      "   macro avg       0.69      0.68      0.68      8400\n",
      "weighted avg       0.70      0.69      0.69      8400\n",
      "\n",
      "Classification Report with Tanh activation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       848\n",
      "           1       0.87      0.93      0.90       975\n",
      "           2       0.71      0.59      0.64       843\n",
      "           3       0.60      0.61      0.61       830\n",
      "           4       0.74      0.55      0.63       776\n",
      "           5       0.70      0.62      0.66       795\n",
      "           6       0.86      0.89      0.88       836\n",
      "           7       0.51      0.53      0.52       839\n",
      "           8       0.59      0.57      0.58       806\n",
      "           9       0.45      0.61      0.52       852\n",
      "\n",
      "    accuracy                           0.68      8400\n",
      "   macro avg       0.69      0.68      0.68      8400\n",
      "weighted avg       0.69      0.68      0.68      8400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Build the neural network model with two different activation functions\n",
    "mlp_relu = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', learning_rate_init=0.01, max_iter=1000)\n",
    "mlp_tanh = MLPClassifier(hidden_layer_sizes=(100,), activation='tanh', solver='adam', learning_rate_init=0.01, max_iter=1000)\n",
    "\n",
    "# Train the models\n",
    "mlp_relu.fit(X_train, y_train)\n",
    "mlp_tanh.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions_relu = mlp_relu.predict(X_test)\n",
    "predictions_tanh = mlp_tanh.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "accuracy_relu = accuracy_score(y_test, predictions_relu)\n",
    "accuracy_tanh = accuracy_score(y_test, predictions_tanh)\n",
    "classification_report_relu = classification_report(y_test, predictions_relu)\n",
    "classification_report_tanh = classification_report(y_test, predictions_tanh)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Accuracy with ReLU activation:\", accuracy_relu)\n",
    "print(\"Accuracy with Tanh activation:\", accuracy_tanh)\n",
    "print(\"Classification Report with ReLU activation:\")\n",
    "print(classification_report_relu)\n",
    "\n",
    "print(\"Classification Report with Tanh activation:\")\n",
    "print(classification_report_tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09e068c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - K Value: 3\n",
      "Benchmark Metric: 0.6245799471895512\n",
      "Accuracy: 0.6342857142857142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       828\n",
      "           1       0.74      0.94      0.83       905\n",
      "           2       0.57      0.63      0.60       803\n",
      "           3       0.50      0.58      0.54       826\n",
      "           4       0.58      0.58      0.58       858\n",
      "           5       0.65      0.54      0.59       793\n",
      "           6       0.86      0.86      0.86       864\n",
      "           7       0.47      0.48      0.48       831\n",
      "           8       0.63      0.47      0.54       835\n",
      "           9       0.47      0.35      0.41       857\n",
      "\n",
      "    accuracy                           0.63      8400\n",
      "   macro avg       0.63      0.63      0.62      8400\n",
      "weighted avg       0.63      0.63      0.63      8400\n",
      "\n",
      "----------\n",
      "KNN - K Value: 7\n",
      "Benchmark Metric: 0.6492122419368648\n",
      "Accuracy: 0.6561904761904762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       828\n",
      "           1       0.78      0.95      0.85       905\n",
      "           2       0.65      0.63      0.64       803\n",
      "           3       0.56      0.58      0.57       826\n",
      "           4       0.68      0.55      0.61       858\n",
      "           5       0.67      0.54      0.60       793\n",
      "           6       0.84      0.88      0.86       864\n",
      "           7       0.44      0.61      0.51       831\n",
      "           8       0.64      0.48      0.55       835\n",
      "           9       0.48      0.40      0.43       857\n",
      "\n",
      "    accuracy                           0.66      8400\n",
      "   macro avg       0.66      0.65      0.65      8400\n",
      "weighted avg       0.66      0.66      0.65      8400\n",
      "\n",
      "----------\n",
      "Random Forest - Number of Trees: 100\n",
      "Benchmark Metric: 0.7026306436140579\n",
      "Accuracy: 0.7065476190476191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88       828\n",
      "           1       0.86      0.95      0.90       905\n",
      "           2       0.72      0.67      0.69       803\n",
      "           3       0.63      0.62      0.63       826\n",
      "           4       0.73      0.63      0.68       858\n",
      "           5       0.72      0.63      0.67       793\n",
      "           6       0.84      0.92      0.88       864\n",
      "           7       0.50      0.59      0.54       831\n",
      "           8       0.69      0.60      0.64       835\n",
      "           9       0.52      0.52      0.52       857\n",
      "\n",
      "    accuracy                           0.71      8400\n",
      "   macro avg       0.71      0.70      0.70      8400\n",
      "weighted avg       0.71      0.71      0.70      8400\n",
      "\n",
      "----------\n",
      "Random Forest - Number of Trees: 200\n",
      "Benchmark Metric: 0.7033110259232114\n",
      "Accuracy: 0.7071428571428572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       828\n",
      "           1       0.86      0.94      0.90       905\n",
      "           2       0.72      0.67      0.70       803\n",
      "           3       0.64      0.63      0.63       826\n",
      "           4       0.71      0.63      0.67       858\n",
      "           5       0.72      0.63      0.67       793\n",
      "           6       0.85      0.93      0.89       864\n",
      "           7       0.50      0.58      0.54       831\n",
      "           8       0.69      0.60      0.64       835\n",
      "           9       0.51      0.52      0.52       857\n",
      "\n",
      "    accuracy                           0.71      8400\n",
      "   macro avg       0.71      0.70      0.70      8400\n",
      "weighted avg       0.71      0.71      0.71      8400\n",
      "\n",
      "----------\n",
      "MLP - Activation: ReLU\n",
      "Benchmark Metric: 0.6976478202958307\n",
      "Accuracy: 0.6977380952380953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       828\n",
      "           1       0.90      0.91      0.91       905\n",
      "           2       0.71      0.67      0.69       803\n",
      "           3       0.63      0.62      0.63       826\n",
      "           4       0.84      0.57      0.67       858\n",
      "           5       0.64      0.67      0.65       793\n",
      "           6       0.87      0.89      0.88       864\n",
      "           7       0.50      0.58      0.54       831\n",
      "           8       0.64      0.60      0.62       835\n",
      "           9       0.48      0.58      0.53       857\n",
      "\n",
      "    accuracy                           0.70      8400\n",
      "   macro avg       0.71      0.70      0.70      8400\n",
      "weighted avg       0.71      0.70      0.70      8400\n",
      "\n",
      "----------\n",
      "MLP - Activation: Tanh\n",
      "Benchmark Metric: 0.6932040618068391\n",
      "Accuracy: 0.6942857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86       828\n",
      "           1       0.90      0.91      0.91       905\n",
      "           2       0.68      0.69      0.68       803\n",
      "           3       0.69      0.56      0.62       826\n",
      "           4       0.77      0.59      0.67       858\n",
      "           5       0.69      0.64      0.66       793\n",
      "           6       0.89      0.89      0.89       864\n",
      "           7       0.47      0.69      0.56       831\n",
      "           8       0.59      0.64      0.62       835\n",
      "           9       0.50      0.44      0.47       857\n",
      "\n",
      "    accuracy                           0.69      8400\n",
      "   macro avg       0.70      0.69      0.69      8400\n",
      "weighted avg       0.70      0.69      0.70      8400\n",
      "\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Benchmark metric function\n",
    "def benchmark_metric(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "k_values = [3, 7]\n",
    "\n",
    "for k in k_values:\n",
    "    # Create the KNN model and train it\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and calculate benchmark metric\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    benchmark_score = benchmark_metric(y_test, y_pred)\n",
    "    \n",
    "    print(\"KNN - K Value:\", k)\n",
    "    print(\"Benchmark Metric:\", benchmark_score)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"----------\")\n",
    "\n",
    "# Random Forest\n",
    "num_trees = [100, 200]\n",
    "\n",
    "for n in num_trees:\n",
    "    # Create the Random Forest model and train it\n",
    "    rf_model = RandomForestClassifier(n_estimators=n)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and calculate benchmark metric\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    benchmark_score = benchmark_metric(y_test, y_pred)\n",
    "    \n",
    "    print(\"Random Forest - Number of Trees:\", n)\n",
    "    print(\"Benchmark Metric:\", benchmark_score)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"----------\")\n",
    "\n",
    "# Multi-Layer Perceptron\n",
    "X_train_normalized = X_train / 255.0\n",
    "X_test_normalized = X_test / 255.0\n",
    "\n",
    "mlp_relu = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', learning_rate_init=0.01, max_iter=1000)\n",
    "mlp_tanh = MLPClassifier(hidden_layer_sizes=(100,), activation='tanh', solver='adam', learning_rate_init=0.01, max_iter=1000)\n",
    "\n",
    "mlp_relu.fit(X_train_normalized, y_train)\n",
    "mlp_tanh.fit(X_train_normalized, y_train)\n",
    "\n",
    "predictions_relu = mlp_relu.predict(X_test_normalized)\n",
    "predictions_tanh = mlp_tanh.predict(X_test_normalized)\n",
    "\n",
    "accuracy_relu = accuracy_score(y_test, predictions_relu)\n",
    "accuracy_tanh = accuracy_score(y_test, predictions_tanh)\n",
    "\n",
    "print(\"MLP - Activation: ReLU\")\n",
    "print(\"Benchmark Metric:\", benchmark_metric(y_test, predictions_relu))\n",
    "print(\"Accuracy:\", accuracy_relu)\n",
    "print(classification_report(y_test, predictions_relu))\n",
    "print(\"----------\")\n",
    "\n",
    "print(\"MLP - Activation: Tanh\")\n",
    "print(\"Benchmark Metric:\", benchmark_metric(y_test, predictions_tanh))\n",
    "print(\"Accuracy:\", accuracy_tanh)\n",
    "print(classification_report(y_test, predictions_tanh))\n",
    "print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7a6131b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAFyCAYAAAD4aN2QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3VUlEQVR4nO3dd7xcRd3H8c83CSV0gVBMCEFEigoIAVFRkSKhi6IUFUEg4ENRlEewI4qCUgRBY0SaCFEUMEAoAg+iFAlNJEAw0hJACL0TEn7PHzMLJ5u9925u7tn6fb9eeWX3tJ05d3d+58zMmVFEYGZm3WtQsxNgZmbN5UBgZtblHAjMzLqcA4GZWZdzIDAz63IOBGZmXc6BoEtIGiUpJA1p0udvJmlGMz67L5JelPSOATzempJul/SCpEMG6rh9fOaHJU3tKQ2Shkq6WNJzks5vRJpagaQHJW1Zx3ZN/X00mwNBE+Qv5yu5AHpG0qWSVml2ulqFpL3yj/KEquWfyMvPrPM410rat6/tImKJiLi/n8mt5evAtRGxZEScvKAHk3SkpNdzof6CpPsknSJp5co2EfG3iFizlzTsAqwILBcRn17QNM1n+vu8CJB0Zv7b7li1/Gd5+V6lJrLLORA0zw4RsQSwMvA48PMmp6c0/bzK+g+wa9W+ewL3DUyq+p2ueqwKTOnPjr2k6fcRsSSwLLAzsBJwazEY9JGGVYH7ImL2AKZpoN0HfKHqcz9N+i5YiRwImiwiXgX+CKxTWSZpEUnHSXpY0uOSxkkamtdtJmmGpK9JekLSY5L2Luw7VNLxkh7K1QB/r+ybfTYf90lJ3yrsd6Sk8yWdk686/yXpXZK+kT9nuqSPF7bfW9I9edv7Je1fWFdJ4+GS/gucUZ3vXF1xt6QRPZya/wL/ArbO2y8LfBCYWHWcTSTdIOlZSf+UtFlefjTwYeCUfOd1Sl4ekg6U9G/g34Vl7+zt/ElaNJ+bp/JnTZa0Yo18XQN8rPC575K0tKSzJc3Mx/22pEF5+70kXS/pRElPA0f2cD4AiIjXI2IKsCswE/ha8Zz3kIbzgO+SAuuLkvbJ230x/w2fkXSFpFUL+ah1nraXdEfO/w2S1i1s/6CkwyTdmc/b7/M5Wxy4DHh7/uwXJb29h+xdDHxI0tvy+zHAnaTvQuVzBuXz91D+Xp4taenC+s/ndU8Vv9+FfY+Q9J+8/g/5ezWP/He5P3+/H5D02d7+Lm0vIvyvwf+AB4Et8+vFgLOAswvrf0Yq8JYFliT9QH6c120GzAaOAhYCtgVeBt6W158KXAsMBwaTCs9FgFFAAL8GhgLrAa8Ba+f9jgReJRW8Q4CzgQeAb+XP2Q94oJDG7YDVAQEfzWnYoCqNx+bPHpqXzcjrvwPcBgzr4fzsBfwd2IN0JQzwP8CvgB8CZ+Zlw4Gn8jkYBGyV3w/L668F9q06dgB/yed2aGHZO/s4f/vnv8NiefmGwFI9pH+uz83n8s/5bzmKdOW7TyGvs4GD83kfWuN4RwLn1Fh+FPCPwjmf0Usa5joG8AlgGrB2/txvAzf0dJ6ADYAngPfn/H+B9D1epPCdvhl4e97nHuCAWmnr4Zydmf+244Ev5WV/AHbP34W98rIv5nS/A1gCuAD4bV63DvAi8JH8Nzshn9vKb+0rwE3AiLz+V8B5ed2onOchwOLA88Caed3KwLubXW6UWiY1OwHd+C//aF4Ens1f1EeB9+Z1Al4CVi9s/wFyIZx/VK8AQwrrnwA2IRWGrwDr1fjMyhd9RGHZzcBu+fWRwF8K63bIaRyc3y+Z91+mhzxdBHy5kMZZwKKF9ZsBj+Qf59+BpXs5P3vlbYaSqs2Wzj/gDzF3IDi8UggU9r0C+EJ+fS21A8HmNZa9s4/z90XgBmDdOv6+b34uqdB8DVinsH5/Uv19Ja8P93G8I6kdCA4A/l04v/MTCC4jB6P8fhApmK9a6zwBvwR+UPX5U4GPFr7Tnyus+wkwrlbaesjjmflvuylwY/6bP56/A8VAcDXwP4X91gReJxXg3wUmFNYtnr+HlUBwD7BFYf3KhX1HMXcgeBb4FDUCcyf+c9VQ83wiIpYhXZkcBPxV0krAMNJV5635FvxZ4PK8vOKpmLuu92XS1dHywKL0Xqf638Lryn4VjxdevwI8GRFzCu+pbC9pG0k3SXo6p3Hb/PkVMyNVexUtA4wl3d0810saAYiIV4BLSVery0fE9VWbrAp8unKecjo2Jf3AezO9h+W9nb/fkoLMBEmPSvqJpIX6ykM+5sLAQ4VlD5HuOPpKT1+GA0/3c99VgZMK5+1p0kVIT+laFfha1blehXQHUNHbd6suEfF30nf928Al+TtQ9HbmPZdDSA3hby+mOSJeIt0hFvNwYSH99wBz8r5U7bcrKdA+ptSZY635zUs7cSBosoiYExEXkL6QmwJPkgrdd0fEMvnf0pEalvvyJKl6Z/XyUpzaMIA/AccBK+aANolUkFTUGtb2GWB74AxJH6rz484m1YP/tsa66aQ7gmUK/xaPiGN6SUNvy3s8f5Hq5r8fEeuQqou2JzVe9+VJ0lXnqoVlI0l3R32lp0e5jWEH4G/zu282Hdi/6twNjYgbekjXdODoqu0Xi4jz6vis+c3fOaS/+dk11j3KvOdyNuki5jFScAJA0mLAclV52KYqD4tGRPFvkRIccUVEbEW6qLiXVKXasRwImkzJTsDbgHsi4g3Sl+5ESSvkbYZL2rqvY+V9TwdOkPR2SYMlfSAX3ANpYdKdzExgtqRtgI/3vsubabwW+Czpyuz9dezyV1Ldf61eVecAO0jaOud10dxoWmmAfpxUl1yX3s6fpI9Jeq+kwaT649dJwbuvY84h1XUfLWnJ3CD71Zz2+SZpIUlrA+eReg6d0McuPRkHfEPSu/Nxl5bUW7fSXwMHSHp//s4uLmk7SUvW8VmPA8sVG3X7cDLpb35djXXnAYdKWk3SEsCPSO1Is0mdLraXtKmkhUltKMUybhzp77AqgKRh+bc3F0krStoxN3S/Rqoi7fNv3c4cCJrnYkkvkgqVo0n12pXufoeTGsRukvQ8cBWpLrQeh5F620wm3e4fywD/nSPiBeAQUgH3DKlRd2KvO829/1+AvYGJkjbsY9uIiKsjYp4qkIiYDuwEfJMUlKYD/8tb+T0J2EWpV0y9/fl7On8rkQqa50lVCn+l/sL8YFK7z/2k+u5zSQFnfuyavy/Pks71U8CGEfHofB4HgIi4kJS3Cfk7dhewTS/b30LqMHAK6W8+jdS+Uc9n3UsqwO/P1TI99RqqbP90/pvXupM4nXR3eB2pM8OrpPNL/v0cSDq/j+V0Fp9fOIl07q6U9AKp3anWxcgg0h3Jo6TvwEdJnRU6lmqfazMz6xa+IzAz63IOBGZmXc6BwMysyzkQmJl1OQcCM7Mu13Zjby+//PIxatSoZifDzKyt3HrrrU9GxLBa69ouEIwaNYpbbrml2ckwM2srkh7qaZ2rhszMupwDgZlZl3MgMDPrcg4EZmZdzoHAzKzLlRoIJI2RNFXSNElH1Fj/v0pzoN4h6S5Jc3qaQ9TMzMpRWiDI47afShradh1gd0nrFLeJiJ9GxPoRsT7wDeCvtYYbNjOz8pR5R7AxMC0i7o+IWcAE0tjxPdmdNGa5mZk1UJmBYDhzz3k6g7nnQ31TnlJuDGn6QzMza6AynyxWjWU9zYKzA3B9T9VCksaSJj1n5MiRA5M6a0mjjri02Umoy4PHbFf3tp2Wp07Lj5V7RzCDwkTSwAjS1G+17EYv1UIRMT4iRkfE6GHDag6VYWZm/VRmIJgMrJEnmV6YVNjPM69tntD6o8CfS0yLmZn1oLSqoYiYLekg4ApgMHB6REyRdEBePy5vujNwZUS8VFZazMx60+3VXaWOPhoRk4BJVcvGVb0/EzizzHSYmVnP/GSxmVmXcyAwM+tyDgRmZl3OgcDMrMs5EJiZdTkHAjOzLudAYGbW5RwIzMy6nAOBmVmXK/XJYitftz8ab2YLzncEZmZdzoHAzKzLORCYmXU5BwIzsy7nQGBm1uUcCMzMupwDgZlZl3MgMDPrcl31QJkfvjIzm5fvCMzMulypgUDSGElTJU2TdEQP22wm6Q5JUyT9tcz0mJnZvEqrGpI0GDgV2AqYAUyWNDEi7i5sswzwC2BMRDwsaYWy0mNmZrWVeUewMTAtIu6PiFnABGCnqm32AC6IiIcBIuKJEtNjZmY1lBkIhgPTC+9n5GVF7wLeJulaSbdK2rPE9JiZWQ1l9hpSjWVR4/M3BLYAhgI3SropIu6b60DSWGAswMiRI0tIqplZ9yrzjmAGsErh/Qjg0RrbXB4RL0XEk8B1wHrVB4qI8RExOiJGDxs2rLQEm5l1ozIDwWRgDUmrSVoY2A2YWLXNn4EPSxoiaTHg/cA9JabJzMyqlFY1FBGzJR0EXAEMBk6PiCmSDsjrx0XEPZIuB+4E3gBOi4i7ykqTmZnNq9QniyNiEjCpatm4qvc/BX5aZjrMzKxnfrLYzKzLORCYmXU5BwIzsy7nQGBm1uUcCMzMupwDgZlZl3MgMDPrcg4EZmZdzoHAzKzLORCYmXU5BwIzsy7nQGBm1uUcCMzMupwDgZlZl3MgMDPrcg4EZmZdzoHAzKzLORCYmXU5BwIzsy7XZyCQtLOkpQvvl5H0iVJTZWZmDVPPHcH3IuK5ypuIeBb4XmkpMjOzhqonENTaZkg9B5c0RtJUSdMkHVFj/WaSnpN0R/733XqOa2ZmA6eeAv0WSScApwIBHAzc2tdOkgbnfbYCZgCTJU2MiLurNv1bRGw/f8k2M7OBUs8dwcHALOD3wPnAq8CBdey3MTAtIu6PiFnABGCn/ibUzMzK0ecdQUS8BMxTrVOH4cD0wvsZwPtrbPcBSf8EHgUOi4gp/fgsMzPrpx4DgaSfRcRXJF1MqhKaS0Ts2MexVWNZ9XFuA1aNiBclbQtcBKxRIy1jgbEAI0eO7ONjzcxsfvR2R/Db/P9x/Tz2DGCVwvsRpKv+N0XE84XXkyT9QtLyEfFk1XbjgfEAo0ePnicomZlZ//UYCCLi1tzgu19EfK4fx54MrCFpNeARYDdgj+IGklYCHo+IkLQxqc3iqX58lpmZ9VOvbQQRMUfSMEkL5wbfukXEbEkHAVcAg4HTI2KKpAPy+nHALsCXJM0GXgF2iwhf8ZuZNVA93UcfBK6XNBF4qbIwIk7oa8eImARMqlo2rvD6FOCUehNrZmYDr55A8Gj+NwhYMi/zVbuZWYeoJxDcHRHnFxdI+nRJ6TEzswar54Gyb9S5zMzM2lBvzxFsA2wLDJd0cmHVUsDsshNmZmaN0VvV0KPALcCOzD220AvAoWUmyszMGqe35wj+CfxT0rl5u5ERMbVhKTMzs4aop41gDHAHcDmApPVzV1IzM+sA9QSCI0kjiT4LEBF3AKPKSpCZmTVWPYFgdnGGMjMz6yz1PEdwl6Q9gMGS1gAOAW4oN1lmZtYo9U5M827gNeA84HngKyWmyczMGqieiWleBr6V/5mZWYfp7YGyXnsG1TExjZmZtYHe7gg+QJpq8jzgH9SecczMzNpcb4FgJWArYHfShDKXAud5TmEzs87SY2NxRMyJiMsj4gvAJsA04FpJBzcsdWZmVrpeG4slLQJsR7orGAWcDFxQfrLMzKxRemssPgt4D3AZ8P2IuKthqTIzs4bp7Y7g86SpKd8FHCK92VYsICJiqZLTZmZmDdDb6KP1PGxmZmZtrtTCXtIYSVMlTZN0RC/bbSRpjqRdykyPmZnNq7RAIGkwcCqwDbAOsLukdXrY7ljgirLSYmZmPSvzjmBjYFpE3B8Rs4AJwE41tjsY+BPwRIlpMTOzHvQZCPLcxdXLDqjj2MNJTyZXzMjLiscZDuwMjKvjeGZmVoJ67gi+I2nzyhtJh1P7yr5arSEpour9z4DDI2JOrweSxkq6RdItM2fOrOOjzcysXvXMR7AjcImk/yVNW7lWXtaXGcAqhfcjgEerthkNTMhdU5cHtpU0OyIuKm4UEeOB8QCjR4+uDiZmZrYA6hmG+klJOwJXAbcCu0REPYXxZGANSasBjwC7kcYsKh57tcprSWcCl1QHATMzK1dvTxa/wNxVOQsD7wB2kdTnA2URMVvSQaTeQIOB0yNiSqV9ISLcLmBm1gJ6e6BsSaU6m1Ui4uH+HDwiJgGTqpbVDAARsVd/PsPMzBZMr43FuQrowgalxczMmqCeXkM3Sdqo9JSYmVlT1NNr6GPA/pIeIg1CVxl0bt1SU2ZmZg1RTyCY54EyMzPrHPV0H30IQNIKwKKlp8jMzBqqniEmdpT0b+AB4K/Ag6TJaszMrAPU01j8A9KcxfflB8C2AK4vNVVmZtYw9QSC1yPiKWCQpEER8X/A+uUmy8zMGqWexuJnJS0BXAf8TtITwOxyk2VmZo1Szx3BTsArwKHA5cB/gB3KTJSZmTVOPb2GXgKQtBRwcekpMjOzhuozEEjaHziKdFfwBvmBMtIAdGZm1ubqaSM4DHh3RDxZdmLMzKzx6mkj+A/wctkJMTOz5qjnjuAbwA2S/gG8VlkYEYeUliozM2uYegLBr4BrgH+R2gjMzKyD1BMIZkfEV0tPiZmZNUU9bQT/J2mspJUlLVv5V3rKzMysIeq5I6hMOP+NwjJ3HzUz6xD1PFC2WiMSYmZmzVHPHQGSPgiMKm4fEWeXlCYzM2ugeuYj+C1wHLApsFH+N7qeg0saI2mqpGmSjqixfidJd0q6Q9Itkjadz/SbmdkCqueOYDSwTkTE/BxY0mDgVGArYAYwWdLEiLi7sNnVwMSICEnrAn8A1pqfzzEzswVTT6+hu4CV+nHsjYFpEXF/RMwCJpBGMn1TRLxYCDCLkxqhzcysgXq8I5B0MalgXhK4W9LNzP1k8Y59HHs4ML3wfgbw/hqfszPwY2AFYLu6U25mZgOit6qh4xbw2KqxbJ4r/oi4ELhQ0kdI02JuOc+BpLHAWICRI0cuYLLMzKyox0AQEX8FkLQa8FhEvJrfDwVWrOPYM4BVCu9HAI/28nnXSVpd0vLVI51GxHhgPMDo0aNdfWRmNoDqaSM4n7nHGJqTl/VlMrCGpNUkLQzsBkwsbiDpnZKUX28ALAw8VU/CzcxsYNTTa2hIbuwFICJm5YK9VxExW9JBwBXAYOD0iJgi6YC8fhzwKWBPSa+TJr7ZdX57J5mZ2YKpJxDMlLRjREyE1PcfqGuSmoiYBEyqWjau8PpY4Nj6k2tmZgOtnkBwAPA7SaeQGoCnA3uWmiozM2uYesYa+g+wiaQlAEXEC+Uny8zMGqWeyesXIdXljwKG5LZdIuKoUlNmZmYNUU/V0J+B54BbKTxQZmZmnaGeQDAiIsaUnhIzM2uKep4juEHSe0tPiZmZNUU9dwSbAntJeoBUNSQgImLdUlNmZmYNUU8g2Kb0VJiZWdP0WTUUEQ+RxgzaPL9+uZ79zMysPdQzQ9n3gMN5a/L6hYBzykyUmZk1Tj1X9jsDOwIvAUTEo6Q5CszMrAPUEwhm5YHgAkDS4uUmyczMGqmeQPAHSb8ClpG0H3AV8Otyk2VmZo1Sz1hDx0naCngeWBP4bkT8pfSUmZlZQ9TTfZRc8P9F0vJ44hgzs47SY9WQpE0kXSvpAknvk3QXcBfwuCQPOWFm1iF6uyM4BfgmsDRwDbBNRNwkaS3gPODyBqTPzMxK1ltj8ZCIuDIizgf+GxE3AUTEvY1JmpmZNUJvgaA4Yf0rVes8r7CZWYforWpoPUnPkwaZG5pfk98vWnrKzMysIXq8I4iIwRGxVEQsGRFD8uvK+4XqObikMZKmSpom6Yga6z8r6c787wZJ6y1IZszMbP6VNnicpMHAqaTRS9cBdpe0TtVmDwAfzUNa/wAYX1Z6zMystjJHEd0YmBYR90fELGACsFNxg4i4ISKeyW9vAkaUmB4zM6uhzEAwHJheeD8jL+vJPsBlJabHzMxqqOvJ4n5SjWU1extJ+hgpEGzaw/qxwFiAkSNHDlT6zMyMcu8IZpAmtKkYATxavZGkdYHTgJ0ioubwFRExPiJGR8ToYcOGlZJYM7NuVWYgmAysIWk1SQsDuwETixtIGglcAHw+Iu4rMS1mZtaD0qqGImK2pIOAK4DBwOkRMUXSAXn9OOC7wHLALyQBzI6I0WWlyczM5lVmGwERMQmYVLVsXOH1vsC+ZabBzMx650nozcy6nAOBmVmXcyAwM+tyDgRmZl3OgcDMrMs5EJiZdTkHAjOzLudAYGbW5RwIzMy6nAOBmVmXcyAwM+tyDgRmZl3OgcDMrMs5EJiZdTkHAjOzLudAYGbW5RwIzMy6nAOBmVmXcyAwM+tyDgRmZl3OgcDMrMuVGggkjZE0VdI0SUfUWL+WpBslvSbpsDLTYmZmtQ0p68CSBgOnAlsBM4DJkiZGxN2FzZ4GDgE+UVY6zMysd2XeEWwMTIuI+yNiFjAB2Km4QUQ8ERGTgddLTIeZmfWizEAwHJheeD8jLzMzsxZSZiBQjWXRrwNJYyXdIumWmTNnLmCyzMysqMxAMANYpfB+BPBofw4UEeMjYnREjB42bNiAJM7MzJIyA8FkYA1Jq0laGNgNmFji55mZWT+U1msoImZLOgi4AhgMnB4RUyQdkNePk7QScAuwFPCGpK8A60TE82Wly8zM5lZaIACIiEnApKpl4wqv/0uqMjIzsybxk8VmZl3OgcDMrMs5EJiZdTkHAjOzLudAYGbW5RwIzMy6nAOBmVmXcyAwM+tyDgRmZl3OgcDMrMs5EJiZdTkHAjOzLudAYGbW5RwIzMy6nAOBmVmXcyAwM+tyDgRmZl3OgcDMrMs5EJiZdTkHAjOzLudAYGbW5UoNBJLGSJoqaZqkI2qsl6ST8/o7JW1QZnrMzGxepQUCSYOBU4FtgHWA3SWtU7XZNsAa+d9Y4JdlpcfMzGor845gY2BaRNwfEbOACcBOVdvsBJwdyU3AMpJWLjFNZmZWpcxAMByYXng/Iy+b323MzKxEQ0o8tmosi35sg6SxpKojgBclTV3AtA2k5YEnB/KAOnYgj9YvnZanTssPdF6eOi0/0Hp5WrWnFWUGghnAKoX3I4BH+7ENETEeGD/QCRwIkm6JiNHNTsdA6rQ8dVp+oPPy1Gn5gfbKU5lVQ5OBNSStJmlhYDdgYtU2E4E9c++hTYDnIuKxEtNkZmZVSrsjiIjZkg4CrgAGA6dHxBRJB+T144BJwLbANOBlYO+y0mNmZrWVWTVEREwiFfbFZeMKrwM4sMw0NEBLVlktoE7LU6flBzovT52WH2ijPCmVxWZm1q08xISZWZdzIGgiSbW6z7atTstPs3TieRzIPEkanYevKbVqu5v4RDZRbiNBkqID6ug6LT+NJGkv4EHgvxFxb3NTMzBKzNP6wD7AG5KuiYjZA3jshsnBcVBEzGl2WnxH0ASSDpT0C0mfkLRSRISktv1bSDpI0i87JT9NsgSwFnCBpJ0kLdXsBA2AUvIUEaeRGmK/DmzRxncGQypBQNIu+S5nw2YkxI3FTZAH5PscaTiNnYE9I+IeSYMi4o3mpm7+5fx8lpSfT9Lm+WkkSUOKV7SSxgAHA38BLoiIh5uWuH4qI095wMrFIuKWwrJ9gF2BYyPi6nb5vuU7gbWAS0gDbn4c+AXwf6SL879ExLmNTFO7RtK2JGkUsEhETAXOysteBSZJ2jki7miXLzOApN8Dd0XED4Cz87LXaNP8NJqkwfl5m0HABsAdEXG5pJnAoaRna8a3U1VbGXmStBhpgMo1JZ0cEbcBRMRvctPD0ZIeiIj7S8nUAMv5vkfSdaRnqP4MvB94gZTP7fLpOa9RafLte4NIOg04EbhI0lcryyPihLx8oqTV26XQlHQisDawmaR1K8vbNT+NlgvCObnAvBr4CHnsrYi4FfgVcKCkj7VREBjQPFUamCPiZVJhOQXYT9KbwzZExG+AvwNfGuj8lCGPojAIICL2Bi4kPUu1QkS8ClxLevbqM5I+3ah0ORA0gKTxwLIRsTPpC7tKHnYDgIg4GTgZ+E6++mlpksaRxoXaDLgNWD0vXwjaLz/NUCgIfwf8Xw6gSHqPpMUj4m/A94H9Jb2tWemcHyXk6c02hYi4G7gYeAj4YlVd+nTg6YHIQ5kqd0ER8YaktwNExNeA04CLJS0VEY+TgsE5wPWNSpsDQcmU5le4MyI+mReNAbYAzpZ0aGHT3wGPA4s0OInzRdL6wOMR8emIeJo0cODxkpaLiNdzewGkL3LL56fRajSiPwG8lIdeOQM4CTgpXyhcB9wNtHSvmDLyJGkV4FxJm1aW5Z5HFwEPAF+V9BlJu5Pa2y4amNyUo1gVJukQ4BxJ50saHhH/Q2ovuFnSMhHxX+CiiJhnAM6yOBCULA+i92t4sxBdmzSm0g+ALyuNx1TZbgiweXNSWp+IuCMivgdvfrlPAq4kzUAn8jDi+cvc8vlppFx//kZ+PSr3drka+ChpiOBfkHrCvArMiYgngTto4ba8EvP0CnAVcJjSgJTAm8HgXOBPpA4KWwBfjIh7BjJfA60QBHYizcw4FniR1L7xnog4hHQHcE3+HTW0StW9hkpU3VCab4dnRcRL+f3OwHoRcWR+PwRYIiKebUJy+5R/9HOq3+crvw9GxJ5Vy1s6P41UuSLMV88XAM+RqjMuAf4WaRY/JJ1F+o7s17zU1qeMPFVdOS8H7EHqVfOjiLixsN37gOeBh9rlOQJJ7wWOB26OiG/nZceR5i34We5csWKuHmoo3xGUJH+hK1dK6yp1qXumEgSyzwOvF7af3aqFZqUhML9etyoonAa8T9K3ACrLWzk/jVaoPx9PutL9PumKdkhEzJK0oqSTgMGVArPSWNqqBjpPVUFgMVJgOZU0gvG3JH0gr9s/f96sVg4CNfL6AnADsKmkLQAi4jDS3dIBkhZuRhCAFr7lbGdVX+gvA+8D9i1cQa0EnAI8HRFHw1w/qpbTV34idRf8MYXGPZuXpCWBmcDtwM+An0TEFZKGkXrXjI+IKXnbtuh2O5B5KnzHvgasC6xMCi5/IFU5flnSrsDWwOYRMb2nYzVbbvh9Pr/eEngq/zuaFBB2lUREXB0RB0haoXIH1Qy+IxhgVYXmQaQHxg4iNWjtkDdbC7gxIvbN27Xs36HO/ABcFoUhxu3NB+0qrxURL5Cucs8l/f2Py6vPBjYsFJhq1SBQdp4k7QGMiYgvAMsCn4+IJ/Lx/0l6gGz3iPjnQOZrIEnaHqhU/RwM/AjYktSusQbwc+AeUlfYjwLkPDaN2whKkr8AOwM7AvuTGojGVN/KttGVX638bB1V46QUA0c3q/xdc5A/mtRL5nJgBWAX4Nb87yDSzHz7Ni2xdSojT0rDTrweEa/k9wcDd5HGE9qa9H17nfRU8UtKvdOeGvDMDRBJHweOJTUGB3ACqafgN4DtgKVJT9/fRxov6U/RArMytuyVaDspXiXl9/sDnyZ9iceSejaMyVUoc1XHtWIQmI/8VB4eepODQJILTJEehJpJKhROB24hda1dDNgTuK8d7gxh4PMkaRtSw/JvJH0nL54FHAV8CNghV5ccARybA1ErB4Gtgd8DUyJiMvAIqbH708CmEbEBqW3jamD1iDilFYIAuI1gQBQKxB1JP5LFSFfM/0PqPrlDDgKDW7lxq2I+89P0kRNbSdU5eS8wlVQVcCGpvny6pCcj4jJJC0VEpbNAy94ZlpGnXGgenf89Dxwl6UbgUlIwuR1YS9IGpOqgPVr1/MCb4yn9GPgusK6k70QaegVJq5Geqob0dPQgUgNxy2jpK5BWJ+lDSg+MAXyBFPUjIk4ENgE2oo0KzU7LT6Op0G1W0snAa6QROG8lPWl7vFIX4uMkDSsUmC3dJjDQeZI0nPTk+ekR8aeI+AtwJrB0RMwgVTONJD2F/0ngs5GeLG5J+S5/B+DAiPg5aRyxdSR9L2/yGrCtpB+R7hC+ExHTmpPa2nxH0E9KoyF+C5gg6RxSPeared1g4Gbg2vwjavlCs9Py02i54JuTq06OIg2udj/pYuufpJ4vAOOAFyNiZmXfVq1OKytPEfGIpDOBzSXdHBE3k+rR3y3pS8BfSePtXEYar7+lrp6r5QujLxfu9m8G5pB6OR0K/ATYC3gnsF+khy1bihuL+0HSpyLiT0qDQu1IephmDeCliDi1lW/za+m0/DRLrk7blnRFuHNEXCfp3cBXSA8NDQUeiYh98vYt37A+0HkqfpckHQ58GHiG1FX0cNKQJIeSuloe2YqFZi2ad+jtIaQ76EOAuyvVRK3KgWA+5dvgbwNfz1dLu5N6N6xB+mH8AxgFPAucFw0cSrY/Oi0/jSZpI9LQ4n/PBdu1wL7AO4B9IuLBfI4HActHGoK81dsESs1TVTvCQaQOCAdGGpQOpcELB7fynYCkD5Kqr56PiEl5WfVIAkOAD5LaPI6INLxGS3Ig6AelIaVnRRosqtJveD/S7fJVpEJzSORx01tdp+WnkZTmmLgIWBQ4KyJ+LGkEqeBcGzg8Ih6s2qel7wQGOk89FJrFYPB14AOkdoO/tXqHitzQ/VNgMrAk8HCkJ4RrbTuE9Ntp2aAGbiyeL7muFOAwYFGlh1+IiEtID9CMBN4F3FMpNAv7tJxOy08z5ALxP6QCYUZe/BjwG9JDQ79RGjOnuE/LBgEY2DzlQnMcsBWwl9LYOkQaqbYyLv9PSAPRHUCLt1tK2ozUA2iXXB12MjBK0jtqbR9pmJWWDgLQ4ie91RS+7C+RJsPYUNILEXFxrmNfmnRL/XqNfVpOp+Wnib5DqisfrzS0wKnAdElXATdFC/d978UC56lQaH48Iu5TGlL6K5LeERH3R344LSLeiIjvKz0s1uqF5mKkALlsfn9TXtbW8244EPRB0o7AvyLigcqyfDUzifRl2FLSGhFxQkScXtivJW//Oy0/zVA5F0qDhM2K3LVRaYycn+cr3XcDt0fEr4r7NDHZvSopT30WmlXBoOUDZkRMyj2bzpW0N6mxexbpTqltuY2gF7lL5SGkJwTPjPTgTGX6vMi3x+8jPWj1IukpyzuiRUfc7LT8NJqkX5LOyyKkvuDPVReGStMofh+YFhFfblJS61Z2niR9BjiGNAfHh4HRwKeijbofV9ozij2DJO1Gaif4b0RslJe1bbdqB4I+KA0XuzXpx3JWRDxULDwL2+1FmjLv9kgzd7WkTstPoyiNrvpe4HukQm0LYMeI+LfeeuiqclW9SES8lvdr2TuBMvLUaYWmpDVJYwIdHxGPF9MtaVvSKMKfi4gbmpnOBeXG4hokHSjpUwARcTVpHJUlgS9IWi2yvO3gvN2ZkYaUbblCs9Py0ySLAOdGxK0RcRBpTJnfSVo5F5iDcoGpdggC2YDmKReaRytNrjK78F2aQBqocDmlHkRvzlnRBhYDFgcOURoqeo6kwTkgTCKNgzRJaajptuVAUKDkQ6RxVM6X9F1JE0hP2U4ljYnyWaX5BIDW/kJ3Wn6a7F5gTaV5d4k0q9zVwKWSFovcf7xYSLZ4EICBz1PHFJqStpR0RETcTpp4Z1HSPMkr5N9IpffcJNJwLA82J6UDw1VDBZIWjYhX89Xz2cCBpD/4h4HV8mbLkmZM+kGksdhbVqflp9EkbUWaKH0GsBxwPqltZXxhm9OAUyLijqYkcj6VkadcsI+OiGMkrUd6gOp14ISIeKJSTSRpCVL105RosbF2KnI16RDSMzSrAsdGxFGFfM0m5etxpYfhvgWsGXkSmnblXkOZpD2BUySNiNR1chnSWOIfiYgzJK0NfArYHli21QvNTstPo0n6PamgnAP8GziPNLXohbnK47JI/e3XIY3H3/IGOk+FQvNkYFWlHkdHSTqbVGh+TVJbFZr5jud1Sf8LfAZ4h6QTI+LQQr72khSkdpVtWzk/9fIdQYGk8cBHgY0i4nmlSdmPITWgXad5HyFv6TrgTstPoygNfXxCRGwm6Z3ABqQf/THAw8APgTdId1UPRsTnmpbYOpWZJ0nbkQrNAJ7JhWblCvqJvHxv0lDStw9gtgaUChPHS3oP8APgDNLcCEMi4muS1gW+ThqWffNo4ZnS5ktEdPU/YD1g0cL7X5BGWFwqv9+PNMTC5lX7qdlp74b8NOkcrg9cVXi/JGl2tj+RphldChgObFHYZlCz091HnjYYyDwBKxZev4c0N8GOpNm5js/L1yV1THgKWK/Z56CP87MlabKdY4ARpCrUPYAJpPGCTgOOydu+ExjR7DQP5L+ubiyW9FXSBBh/lHSSpNUjjbfzO+BmSUtExK9Jfah3Le4b+RvRSjotP80SqW58pqSz8vsXgOuBO0lVa89HxCORemC19AByFZGGCHk6V28sUJ5ym8Bdko5RGoNoCqmtYQ/SREZLSzomIu4EjiQFgVa/cn6C1Ni9L2lKyV+TRkX9F/AQcDywuqQfRMS0SPMmdIyuDQRKY4PcSOoy9wDpqmispNuBv5Em37hS0pIRcWJE7N+81Pat0/LTaJJ2UZowpeIrwGylyViINLn4rcCHNe/0nC0ZBCQdK+l4SSfmRfsDbwxAnjqu0MxBazSp/WQlUk+hb5HG4do+Iu4hBbVfNCuNZerKQCBpH+BHEXEjqTfN08CVpMbUb5Ju/e4hzcr17byPcuNYy+m0/DRa7lJ7LKl74Mi8+EngOOBtkq7Idd5fAh5r1YK/SNKvgTVJDcLbSjo+Ip4hTae4QHnq1EIzp3tb0nwIwyNiU1Jnitvy+inRInMMD7SubCyWtC+wcUSMze+3I42OOAM4IyKekrQ46Za25Z8Y7LT8NFJuOP0h6U7qPcAywEkR8XBhm+NJ3SGXireG6m7ZhvXcRfQA0giZkYPbKcAn462nfY8jdYXsd54kbUh67mDviLhQ6ZmVWZEmbm9bkjYmXUh9LSJ+0+z0NEJXBQJJm0fENZJ2AD4ahTHEC4XndODPUejn3Kp1wJ2Wn0ZTmmN3ptIYS08DG5MaPBcFTo2I+3vYr2XPn6RlSVNKrh0RtytN8rICcA2wdVTNI1DYr1956tRCMwe5yaSJeM5odnrK1jVVQ0qTbVyVr56foWrY2Ii4lNTQtRZpdq7iupb70XdafhpNaUjknyk9VftsJP8AJpJGk9xH0kqSvixpqeK+rXr+JH0YOImU/rshjSwbEY+Qnnydnrfbd6DaOSLNN7wF8Gul0Tg7QkTcCmwIdMUddNc8UBZper33kybEvht4PveyeYn0w3mAVJieGRHXNy+l9em0/DTBfaSC8fVcfTIk0iQi/5D0PLA7qV3l7xFxUlNTWr+pwKO5UH9Ncw/s9jKwmqQfkDqJnTZQHxoRt+Yr6JcH6pitIFr4mYeB1lVVQwC5gexKUiH5VeBjpKctnwdmtkMdcFGn5aeRJP2BNH3ivvl9cWTJe4EbI2Lv/L4tzl+NPC1Mat+4ntSwe3HkoaTbJU9Wvq4LBACS3g1cR6r/u6jJyVlgnZafslXqwyUNJTUS3xwRP8zrFiI9UPSdiPhicfvmpbhvveUprx9H+r3vX9y+Scm1FtOVgQBA0kakwdaOjYhjC8vb8iqp0/JTNr013v7GpG6PD0TE4TW2a5sCs7c8KU8PmV+3TZ6sMbqmsbha7uK2PW+NwllZ3paFZqflZyDlLqKV1++FuYbbvo3UB360pNMkfUTS8pXtW7XAnI88nZ4bxl/I26pV82TN07V3BNU67cq50/LTX5KWJg19sCrwLuCCiDinh20PIw289gZpGObZDUvofOjEPFlzORBYx8u9qyaR5tx9f15WnEpxSLGAVJ7HoTmprU8n5smax4HAOlJVD6AVgMNJI2w+BhyZG1bb6q6pE/NkraFr2wisc+XG0DmSBkm6ljR0xNdJwyysRhp9FdKUimv0cJiW0ol5stbhQGAdp3JlTHq+4oaIuCZfSd9DevJ2VUn/AdaJiH83M6316sQ8WevomieLreuMJE3I8zO9NYPWHGAcaXKezSPiMmirhvVOzJO1AN8RWEdQmnO36ElgZdKEKVsDV5EKzQ9ExGuFAnNQqxaYnZgna02+I7C2V6w/J02SMhO4lzRe0PCImJq32wpYvLhvq/ap78Q8WetyryHrCLn+/ELemn7xMlJ9+b2SViHNmvVaRHy+icmcL52YJ2tNviOwtlUYX0ekKpPbSJOMn0MaH/9epfH5nwOurIy42cpDLHRinqz1uY3A2lKhwBxEaiz9ILA+6SGriyLixFyYHgcs0w4FZifmydqDA4G1pULBdyTwUET8kTS/wMrAaZKWASYAc6Iw7WQrF5idmCdrD64asralNDvbx4HfAkTEl5WmnbyI9N1+MCIOzNu2RXfKTsyTtT43Flvb0NwzbpEbTA8mTTh/VuSZ2CStTPpuP5rft2zVSSfmydqPA4G1hcJY+4OAo0jTIt5Cakw9FBBwSUTcULVfy141d2KerD25jcBanqShucAUcAGwAvAU8BvSxOknAgHsIekdxX1btcDsxDxZ+3IbgbU0SUeRpuG8CtgAWDgixuZ1k4GJpLH5zwDWjzwLVyvrxDxZe/MdgbUsSacCG0TEVXnRM8BLkt6ex9u/DfgJsFZETMu9bCoPYrWkTsyTtT8HAmtJkk4G3hkR2+f3nyQVmq8APwRWkbQIsBWwWHHfVq066cQ8WWdwILCWkxtPhwHT8vuDgWOBVyNiT1Ij6g9JQy48EhE/a1JS69aJebLO4V5D1lIqPWIkLQycTnqYamngk8WHqCStBLwtIu7J71u2O2Un5sk6iwOBtZxCt8qFSb1nlgQOIA2wNqfG9i3fnbIT82Sdw1VD1nJygTk4ImaR+tMPIo20ObyH7Vu+wOzEPFnn8B2BNV3107WF5UMiYna+ij4NWAg4MCKebngi51Mn5sk6l+8IrKk096Ts+0laPxeS5AJzSL6K3g+4th0KzE7Mk3U23xFY0xQaUQVcQrowWY70dO2kiJietxsSEbOr92tKovvQiXmyzuc7AmuKXHVSKfhGAbdExDbAN4BNgB0kjYB0FV3ct1ULzE7Mk3UH3xFYw1VNwHINaT7e9YG1c9XJlsCewBTg1+1QddKJebLu4TsCa7hC3/hvATcAh5Hm5P1jvqq+Cvg98Gy7FJidmCfrHr4jsIYq1KF/E9gGOCYiLpW0GHAqqT5956ox+lu6/rwT82TdxXcE1hCSBsNcdeEXAfcDm0p6R0S8DByY1x1S3LdVC8xOzJN1J98RWOmqJmD5JvBf4B7gXuAE4G7gjxHxH0kL566VLa0T82Tdy3cEVrp4awKWicAapGkY/0AaZfMwYG1gL0krVArMVh92uRPzZN3LE9NYaSSNAf6S68Y/BMyOiC/kdZcCVwCfAE4GRkfEE5V9W7XqpBPzZOY7AiuFpPeRZtn6aq5LfwZYtLI+j7A5HlgtIm6LiPF5v5a9au7EPJmBA4GVJCJuB84HVgfGRsQU4EVJF0taKG/2IdIY/cX9WvaquRPzZAauGrIBVtUtcidgRWBDSbMiYhdJvwcukDQUeDAixjUtsXXqxDyZFTkQ2ICqFJiSfgM8BXwZ+CywgaQ3ImJXScOBYRFxR962pSdg6cQ8mRU5ENiAKF41K827uxhwQUS8JOk8Ul36gZJWJj1w9Uhhv5YsMDsxT2a1uI3AFlhxsLX8+jXSeDt7S1onIl4AzgUeBmYUC8lWrT/vxDyZ9cQPlNkCqRpsbRxpLt4TgSeBnYHNgDOATwP/johv5/1adoiFTsyTWW8cCGyB5e6Rp5FG3HwW+BipH/29pOGXPwg8FxHfrGzf6gVmJ+bJrCcOBLbAJB0C7BYRH8zv9wZ2BM6KiIuqtm2LRtROzJNZT9xGYPMtV5lUXi9BumIeKukwgIg4A/gz8HVJGxb3bdUCsxPzZFYv3xHYfCkMtiZgTeDliHhY0i7AlsAdlX70kjaNiL83M7316MQ8mc0PBwKbb/nq+TJgKmlwtbMi4hxJnwLGAPdGxPGF7Vu+/rwT82RWLz9HYPMlj7EzAbgaOJtUeP5Q0nIRcZKkxYGFivu0eoHZiXkymx8OBNYnSZuQ+ss/ExGvSBoPXAdMAn5OGnv/IklD2uWquRPzZNZfDgTWK0m/AkaTZt76j6TvA1cB6wGPRMTpklYiXU0PL+7bqgVmJ+bJbEG415D1SNI5wGxSoXkW6cGqEbkwHASsJOkTpP72N0XEV/N+LTvscifmyWxBORBYTXkQtT2AuyK5BFgE+IikFSPiNuBMYH1gekT8PO/XslUnnZgns4HgXkPWI0mjgcuBr0XEWZKmk4ZZeI404NovgUkRMTNv3/IPVnVinswWlAOB9UrSRsCVwGvAoRFxnqRhpGGYIyJOamoC+6ET82S2IBwIrE+S1gX+ChwYEefWWN92VSedmCez/nKvIetTRNwpaSvgSknDI+KnVevbrsDsxDyZ9Zcbi60uEXELsD1pvt6O0Il5MusPVw1Zv3Ri1Ukn5smsHg4EZmZdzlVDZmZdzoHAzKzLORCYmXU5BwIzsy7nQGCWSQpJvy28HyJppqRL5vM4D0pafkG3MWsUBwKzt7wEvEfS0Px+K+CRJqbHrCEcCMzmdhmwXX69O3BeZYWkZSVdJOlOSTflYSqQtJykKyXdnuc6UGGfz0m6WdIdkn6VZ0OjsH5xSZdK+qekuyTtWn4WzebmQGA2twnAbpIWBdYF/lFY933g9ohYF/gmaVpLgO8Bf4+I9wETgZEAktYGdgU+FBHrA3NIA9sVjQEejYj1IuI9pJFRzRrKYw2ZFeQxiEaR7gYmVa3eFPhU3u6afCewNPAR4JN5+aWSnsnbbwFsCEzO89oMBZ6oOua/gOMkHQtcEhF/G/hcmfXOgcBsXhOB44DNgOUKy2vNUhZV/xcJOCsivtHTB0XEfZI2BLYFfizpyog4ql+pNusnVw2Zzet04KiI+FfV8uvIVTuSNgOejIjnq5ZvA7wtb381sIukFfK6ZSWtWjygpLcDL0fEOaTgs0EZGTLrje8IzKpExAyg1uQ0RwJnSLoTeBn4Ql7+feA8SbeR5jh4OB/nbknfJg11PQh4HTgQeKhwzPcCP5X0Rl7/pYHPkVnvPOicmVmXc9WQmVmXcyAwM+tyDgRmZl3OgcDMrMs5EJiZdTkHAjOzLudAYGbW5RwIzMy63P8D4BEyaOYM1LsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Benchmark metric function\n",
    "def benchmark_metric(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "# Initialize lists to store benchmark scores\n",
    "knn_scores = []\n",
    "rf_scores = []\n",
    "mlp_relu_scores = []\n",
    "mlp_tanh_scores = []\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "k_values = [3, 7]\n",
    "\n",
    "for k in k_values:\n",
    "    # Create the KNN model and train it\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and calculate benchmark metric\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    benchmark_score = benchmark_metric(y_test, y_pred)\n",
    "    knn_scores.append(benchmark_score)\n",
    "\n",
    "# Random Forest\n",
    "num_trees = [100, 200]\n",
    "\n",
    "for n in num_trees:\n",
    "    # Create the Random Forest model and train it\n",
    "    rf_model = RandomForestClassifier(n_estimators=n)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and calculate benchmark metric\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    benchmark_score = benchmark_metric(y_test, y_pred)\n",
    "    rf_scores.append(benchmark_score)\n",
    "\n",
    "# Multi-Layer Perceptron\n",
    "X_train_normalized = X_train / 255.0\n",
    "X_test_normalized = X_test / 255.0\n",
    "\n",
    "mlp_relu = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', learning_rate_init=0.01, max_iter=1000)\n",
    "mlp_tanh = MLPClassifier(hidden_layer_sizes=(100,), activation='tanh', solver='adam', learning_rate_init=0.01, max_iter=1000)\n",
    "\n",
    "mlp_relu.fit(X_train_normalized, y_train)\n",
    "mlp_tanh.fit(X_train_normalized, y_train)\n",
    "\n",
    "predictions_relu = mlp_relu.predict(X_test_normalized)\n",
    "predictions_tanh = mlp_tanh.predict(X_test_normalized)\n",
    "\n",
    "mlp_relu_scores.append(benchmark_metric(y_test, predictions_relu))\n",
    "mlp_tanh_scores.append(benchmark_metric(y_test, predictions_tanh))\n",
    "\n",
    "# Create a bar chart\n",
    "models = ['KNN (k=3)', 'KNN (k=7)', 'Random Forest (100 trees)', 'Random Forest (200 trees)', 'MLP ReLU', 'MLP Tanh']\n",
    "scores = knn_scores + rf_scores + mlp_relu_scores + mlp_tanh_scores\n",
    "\n",
    "plt.bar(models, scores)\n",
    "plt.title('Benchmark Metrics for Different Models')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Benchmark Metric')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7133a7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
